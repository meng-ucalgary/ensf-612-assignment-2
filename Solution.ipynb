{"cells":[{"cell_type":"markdown","source":["# ENSF-612 Assignment 2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8571f506-767c-4629-95b6-292e13df06c7"}}},{"cell_type":"markdown","source":["#### Install modules"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"764d84f6-cf96-4af4-8bc3-109e039fd85a"}}},{"cell_type":"code","source":["!pip install nltk pyspellchecker beautifulsoup4"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"458dd6d7-8c77-4d1f-a56b-34fade5086a5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\r\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\r\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (4.10.0)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\r\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.2)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4) (2.3)\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\r\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\r\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (4.10.0)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\r\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.2)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4) (2.3)\r\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["#### Import Modules"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"224ea8c1-afce-4630-8f30-65b9459907c5"}}},{"cell_type":"code","source":["from spellchecker import SpellChecker\nimport nltk\nimport string\nimport re\nimport math\nfrom bs4 import BeautifulSoup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6eac248c-a0f5-4ab2-9226-abb9dca7ef90"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Download `nltk` data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff97fede-f898-4dd3-97b4-f7bb46bdf1ce"}}},{"cell_type":"code","source":["nltk.download(['punkt', 'stopwords', 'maxent_treebank_pos_tagger', 'averaged_perceptron_tagger', 'wordnet'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7687b31f-f9df-4701-b2e7-873ff914ab18"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package maxent_treebank_pos_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nOut[3]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package maxent_treebank_pos_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nOut[3]: True"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Question 1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0455bd8-770e-4b7a-9aa0-f0b9ae1164f9"}}},{"cell_type":"markdown","source":["#### 1. Task 1\n\nTo fix typos, we can use `pyspellchecker` that uses Levenshtein Distance algorithm to find permutations of the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list to determine the correct word.\n\nThe below steps are followed for this task -\n\n1. Initialize `SpellChecker`, and remove the word \"jsut\" from the `pyspellchecker`, as it according to `pyspellchecker`, \"jsut\" is a valid english word.\n1. Tokenize the original sentence into words using `word_tokenize` of `nltk`.\n1. Pass each word to `SpellChecker` function `correction` to get the word without typo. The already correct word is returned as it is. Store the fixed words in a list.\n1. Join the list back to get the sentence."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae3c60eb-9063-4ad9-ac0c-cd80a5e942cd"}}},{"cell_type":"code","source":["# 1. removing \"jsut\" word\nspell = SpellChecker()\nspell.word_frequency.remove('jsut')\n\n# 2. tokenize the given sentence\ngiven_sentence = 'this is jsut graet!'\ngiven_words = nltk.word_tokenize(given_sentence)\n\n# 3. fix typo in each word, and store in list fixed_words\nfixed_words = []\nfor w in given_words:\n  fixed_words.append(spell.correction(w))\n\n# 4. form the sentence again\nfixed_sentence = \" \".join(fixed_words)\n\nprint(fixed_sentence)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a74383eb-0b63-4b94-b3ef-2373d350a7bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"this is just great !\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["this is just great !\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["#### 2. Task 2\n\nSo, there were two typos in the given sentence - 'jsut' and 'graet'.\n\n1. jsut  \n    Two replace are required for letter 's' to 'u' and letter 'u' to 's'\n1. graet  \n    Two replace are required for letter 'a' to 'e' and letter 'e' to 'a'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d34bdeed-7cd8-4aa6-941d-3e7e5f92d88f"}}},{"cell_type":"markdown","source":["## Question 2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fea86eec-569d-4db3-8acc-7ac74813c5f6"}}},{"cell_type":"markdown","source":["#### Importing CSV files\n\nThe csv files are uploaded to DBFS. We use the spark `read` function to import csv for all three programming languages. Also, we change the datatype of column \"Score\" to integer."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c11d483a-4e88-4b49-98a2-63aca2cb7583"}}},{"cell_type":"code","source":["def read_CSV_to_DF(filepath):\n  \"\"\"\n  Reads a csv file into a spark dataframe\n  \"\"\"\n  df = (spark.read\n        .option(\"multiline\", \"true\")\n        .option(\"quote\", '\"')\n        .option(\"header\", \"true\")\n        .option(\"escape\", \"\\\\\")\n        .option(\"escape\", '\"')\n        .csv(filepath)\n        )\n  \n  return df\n\n\n# importing files from DBFS\ndf_jv = read_CSV_to_DF('/FileStore/assignment_2/SO_Java.csv')\ndf_py = read_CSV_to_DF('/FileStore/assignment_2/SO_Python.csv')\ndf_js = read_CSV_to_DF('/FileStore/assignment_2/SO_Javascript.csv')\n\n# cast the Score to int\ndf_jv = df_jv.withColumn(\"Score\", df_jv[\"Score\"].cast(\"int\"))\ndf_py = df_py.withColumn(\"Score\", df_py[\"Score\"].cast(\"int\"))\ndf_js = df_js.withColumn(\"Score\", df_js[\"Score\"].cast(\"int\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1004f712-825c-41b5-b141-5fee8f883528"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 1. Pre-Processing\n\nThe textual contents in the files are preprocessed using various methods described below."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b1dad410-690e-47d3-87df-9e57173e3fb0"}}},{"cell_type":"markdown","source":["##### a. Merging of Title and Body column\n\nThe columns \"Title\" and \"Body\" are merged together and stored as \"Title_Body\", so that any operation applied is reflected to contents of both the columns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b05349bb-7152-4943-acf0-17864221c626"}}},{"cell_type":"code","source":["@udf\ndef merge_cols(a, b):\n  \"\"\"\n  UDF to merge two columns\n  \"\"\"\n  c = a + \" \" + b  \n  return c\n\n\ndf_jv = df_jv.select(\"*\", merge_cols(\"Title\", \"Body\").alias(\"Title_Body\")).drop(\"Body\")\ndf_py = df_py.select(\"*\", merge_cols(\"Title\", \"Body\").alias(\"Title_Body\")).drop(\"Body\")\ndf_js = df_js.select(\"*\", merge_cols(\"Title\", \"Body\").alias(\"Title_Body\")).drop(\"Body\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9742e84e-f61f-4d80-a9cc-0e6281b3e535"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### b. Extraction of textual contents\n\nAfter removing all the hyperlinks and code snippets, textual contents are extracted from the column \"Title_Body\". The case of all words is also lowered. This extracted textual contents in lowercase are stored in column \"Text\"."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e184d5c-9849-41fb-aa03-663b481b8c62"}}},{"cell_type":"code","source":["@udf\ndef preprocess_text(body):\n  \"\"\"\n  UDF to extract textual contents\n  \"\"\"\n\n  soup = BeautifulSoup(body)\n\n  # remove hyperlinks\n  urls  =  soup.find_all('a')\n  if len(urls) > 0: soup.a.clear()\n\n  # remove code\n  codes = soup.find_all('code')\n  if len(codes) > 0: soup.code.clear()\n\n  # remove preformatted text\n  pres = soup.find_all('pre')\n  if len(pres) > 0: soup.pre.clear()\n\n  # all the remaining is textual content\n  text = soup.get_text().lower()\n\n  return text\n\n\ndf_jv = df_jv.select(\"*\", preprocess_text(\"Title_Body\").alias(\"Text\")).drop(\"Title_Body\")\ndf_py = df_py.select(\"*\", preprocess_text(\"Title_Body\").alias(\"Text\")).drop(\"Title_Body\")\ndf_js = df_js.select(\"*\", preprocess_text(\"Title_Body\").alias(\"Text\")).drop(\"Title_Body\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e437384b-480c-4802-9f7a-dd88ce6d01dc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### c. Tokenizing and stopwords removal\n\nThe column \"Text\" is tokenized from a string to a list of words using `nltk`, and then all stopwords are removed. Also, words smaller than length of three are also removed. The result is stored in column \"Text_no_stopwords\"."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"381aa419-fabe-423e-a187-1dcd5113261a"}}},{"cell_type":"code","source":["@udf\ndef remove_stopwords(text):\n  \"\"\"\n  UDF to tokenize and remove stopwords and words of length\n  two or less.\n  \"\"\"\n  \n  stopwords = nltk.corpus.stopwords.words('english')\n  sentences = nltk.sent_tokenize(text)\n  filtered_words = []\n\n  for sentence in sentences:\n    words = nltk.word_tokenize(sentence)\n\n    for word in words:\n      if len(word) < 3:\n        continue\n      \n      if word in stopwords:\n        continue\n      \n      filtered_words.append(word)\n\n  return filtered_words\n\n\ndf_jv = df_jv.select(\"*\", remove_stopwords(\"Text\").alias(\"Text_no_stopwords\")).drop(\"Text\")\ndf_py = df_py.select(\"*\", remove_stopwords(\"Text\").alias(\"Text_no_stopwords\")).drop(\"Text\")\ndf_js = df_js.select(\"*\", remove_stopwords(\"Text\").alias(\"Text_no_stopwords\")).drop(\"Text\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"500740c9-2ada-41e4-9ba7-594aee3da062"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### d. Noise removal\nThe punctuation, considered as noise, is removed. The results is then stored in column \"Text_cleaned\"."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13b8f9ea-3dff-4afa-9a2c-3ee0d04e1bde"}}},{"cell_type":"code","source":["regex = re.compile('^[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+$')\n\n@udf\ndef remove_noise(text):\n  \"\"\"\n  UDF to remove punctuation\n  \"\"\"\n  \n  text_no_noise = []\n  \n  for word in text:\n    if bool(regex.match(word)) == False:\n      text_no_noise.append(word)\n    \n  return text_no_noise\n\n\ndf_jv = df_jv.select(\"*\", remove_noise(\"Text_no_stopwords\").alias(\"Text_cleaned\")).drop(\"Text_no_stopwords\")\ndf_py = df_py.select(\"*\", remove_noise(\"Text_no_stopwords\").alias(\"Text_cleaned\")).drop(\"Text_no_stopwords\")\ndf_js = df_js.select(\"*\", remove_noise(\"Text_no_stopwords\").alias(\"Text_cleaned\")).drop(\"Text_no_stopwords\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e464558a-4960-4bb4-b84a-e0ba849d58eb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### e. Stemming\n\nAll the words in the column \"Text_cleaned\" are now kept only in their root form. The Snowball stemmer is used for this purpose. The result is stored in column \"Text_stemmed\"."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c669438-7e20-4886-b746-064e8215e08c"}}},{"cell_type":"code","source":["@udf\ndef word_stem(text):\n  \"\"\"\n  UDF to stem the words\n  \"\"\"\n  \n  sb = nltk.stem.SnowballStemmer(language='english')\n  \n  stemmed_words = []\n  \n  for t in text:\n    st = sb.stem(t)\n    stemmed_words.append(st)\n  \n  return stemmed_words\n\n\ndf_jv = df_jv.select(\"*\", word_stem(\"Text_cleaned\").alias(\"Text_stemmed\")).drop(\"Text_cleaned\")\ndf_py = df_py.select(\"*\", word_stem(\"Text_cleaned\").alias(\"Text_stemmed\")).drop(\"Text_cleaned\")\ndf_js = df_js.select(\"*\", word_stem(\"Text_cleaned\").alias(\"Text_stemmed\")).drop(\"Text_cleaned\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf61c10e-8788-4023-93d9-7a75d3b91b36"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2. Highest scored question without accepted answer\n\nThe pre-processed dataframe is filtered to have only those rows that don't have any accepted answer. Then, that dataframe is sorted in descending order on the column \"Score\", to have highest scored question on top. Only the topmost question with highest score is selected. If more than one question has same highest score, only the first to appear in the dataframe is selected."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f49980ca-1d9d-47c2-9cef-a34c10444669"}}},{"cell_type":"code","source":["def highest_unanswered(pyspark_df):\n  \"\"\"\n  Returns the Row that has highest score question\n  without any accepted answer\n  \"\"\"\n  \n  unanswered_df = pyspark_df.filter(pyspark_df[\"AcceptedAnswerId\"].isNull())\n  unanswered_df = unanswered_df.sort(\"Score\", ascending=False)\n  \n  return unanswered_df.first()\n\n\nq_jv = highest_unanswered(df_jv)\nq_py = highest_unanswered(df_py)\nq_js = highest_unanswered(df_js)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f0144cb-0d50-402a-aef0-5a48f55d8297"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 3. Cosine Similarity\n\nBelow is the udf to calculate cosine similarity of parameter `t1` with global variable `t2`. Both `t1` and `t2` are list of words. The formula given in the slides is implemented in pure python.\n\nAlso, there is a utility function to call the udf, that will be used by dataframe of all three programming languages. This function filters to keep only questions that have accepted answers, and stores the cosine similarity in the column \"Similarity\". The dataframe is then sorted based on the cosine similarity score in descending order."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3830db6-206c-4cb5-850e-a9850a1fd399"}}},{"cell_type":"code","source":["@udf\ndef cosine_similarity(t1):\n  \"\"\"\n  UDF to calculates the cosine similarity of t1 with\n  with highest scored question without accepted answer\n  \"\"\"\n  \n  d = list(set(t1 + t2))\n  \n  dt1 = []\n  dt2 = []\n  \n  for word in d:\n    if word in t1:\n      dt1.append(1)\n      \n    else:\n      dt1.append(0)\n  \n    if word in t2:\n      dt2.append(1)\n      \n    else:\n      dt2.append(0)\n  \n  numerator = 0\n  sum_sq_dt1 = 0\n  sum_sq_dt2 = 0\n  \n  for i in range(0, len(dt1)):\n    numerator += dt1[i] * dt2[i]\n    \n    sum_sq_dt1 += dt1[i] * dt1[i]\n    sum_sq_dt2 += dt2[i] * dt2[i]\n    \n  denominator = math.sqrt(sum_sq_dt1 * sum_sq_dt2)\n  \n  if denominator == 0:\n    return 0\n  \n  return numerator/denominator\n\n\ndef df_with_similarity(pyspark_df):\n  \"\"\"\n  Returns a pyspark dataframe with column Similarity\n  calculated using cosine similarity\n  \"\"\"\n  \n  df = pyspark_df.filter(pyspark_df[\"AcceptedAnswerId\"].isNotNull()).select(\"*\", cosine_similarity(\"Text_stemmed\").alias(\"Similarity\")).sort(\"Similarity\", ascending=False)\n  \n  return df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e7386cc-ddce-4cf1-b1a5-1f2e5707d10e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### a. Calculating similarity of java df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15c5be5a-df7f-4138-a121-7cd16cdcd03e"}}},{"cell_type":"code","source":["t2 = q_jv[\"Text_stemmed\"].strip('][').split(', ')\nanswered_df_jv = df_with_similarity(df_jv)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d5a1f46-c988-4ec6-a4e6-331b81295253"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### b. Calculating similarity of python df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c47104a2-cac1-4c5f-9ead-ba1142d51e13"}}},{"cell_type":"code","source":["t2 = q_py[\"Text_stemmed\"].strip('][').split(', ')\nanswered_df_py = df_with_similarity(df_py)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8412ccc4-5115-4a5d-9a97-8eeae6c5603d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### c. Calculating similarity of javascript df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1385b3fb-2866-4084-91e7-b9216e63b0da"}}},{"cell_type":"code","source":["t2 = q_js[\"Text_stemmed\"].strip('][').split(', ')\nanswered_df_js = df_with_similarity(df_js)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"471ab2cf-4e16-4625-8a3d-f1ed10a232d8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 4. Printing most similar question"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32e37dab-fe5a-4cae-842e-8942cfc9f61a"}}},{"cell_type":"code","source":["def print_top_n(df, n):\n  \"\"\"\n  Prints top n Title of df\n  \"\"\"\n  \n  top_n = df.take(n)\n  \n  for i in range(0, n):\n    print(\"  {}. [Id = {}] {}\".format(i+1, top_n[i][\"Id\"], top_n[i][\"Title\"]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5c0f262-e16a-4a3c-ac2a-10b47b50d143"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Three most similar questions in Java"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4d4b938-cf2e-4831-a931-d327686884a3"}}},{"cell_type":"code","source":["print(\"The highest scored question in Java without any accepted answer is-\\n  [Id = {}] {}\\n\".format(q_jv[\"Id\"], q_jv[\"Title\"]))\n \nprint(\"And the top three most similar questions with accepted answers are\")\n\nprint_top_n(answered_df_jv, 3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c0c00d5-4f6e-41d0-a541-797fe3eedbdc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"The highest scored question in Java without any accepted answer is-\n  [Id = 109383] Sort a Map<Key, Value> by values\n\nAnd the top three most similar questions with accepted answers are\n  1. [Id = 48663774] Add a value to all Sets (values in a map) in a Map<String, Set<String>>\n  2. [Id = 16954286] Initialize map of map in java\n  3. [Id = 32078074] Java: Array sorting\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["The highest scored question in Java without any accepted answer is-\n  [Id = 109383] Sort a Map<Key, Value> by values\n\nAnd the top three most similar questions with accepted answers are\n  1. [Id = 48663774] Add a value to all Sets (values in a map) in a Map<String, Set<String>>\n  2. [Id = 16954286] Initialize map of map in java\n  3. [Id = 32078074] Java: Array sorting\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Three most similar questions in Python"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"faa939ef-220f-4208-a383-a89f715a8af6"}}},{"cell_type":"code","source":["print(\"The highest scored question in Python without any accepted answer is-\\n  [Id = {}] {}\\n\".format(q_py[\"Id\"], q_py[\"Title\"]))\n\nprint(\"And the top three most similar questions with accepted answers are\")\n\nprint_top_n(answered_df_py, 3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d41a60a5-8abb-414a-a0e8-83888ef7d5db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"The highest scored question in Python without any accepted answer is-\n  [Id = 455612] Limiting floats to two decimal points\n\nAnd the top three most similar questions with accepted answers are\n  1. [Id = 32778666] How to change all True values in list on False and vice versa\n  2. [Id = 32300907] Counting number of unique values in subset of sorted array\n  3. [Id = 63869688] Returning large data array from Python to Java using Chaquopy\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["The highest scored question in Python without any accepted answer is-\n  [Id = 455612] Limiting floats to two decimal points\n\nAnd the top three most similar questions with accepted answers are\n  1. [Id = 32778666] How to change all True values in list on False and vice versa\n  2. [Id = 32300907] Counting number of unique values in subset of sorted array\n  3. [Id = 63869688] Returning large data array from Python to Java using Chaquopy\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Three most similar questions in JavaScript"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d7e2828-5f1a-442d-958c-041ebe66a832"}}},{"cell_type":"code","source":["print(\"The highest scored question in Javascript without any accepted answer is-\\n  [Id = {}] {}\\n\".format(q_js[\"Id\"], q_js[\"Title\"]))\n\nprint(\"And the top three most similar questions with accepted answers are\")\n\nprint_top_n(answered_df_js, 3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac788633-c31e-4aad-9a3d-f84447aae350"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"The highest scored question in Javascript without any accepted answer is-\n  [Id = 8567114] How to make an AJAX call without jQuery?\n\nAnd the top three most similar questions with accepted answers are\n  1. [Id = 890807] Iterate over a Javascript associative array in sorted order\n  2. [Id = 48863885] Converting array of object to en object with key : value dynamic\n  3. [Id = 417645] How to convert variable name to string in JavaScript?\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["The highest scored question in Javascript without any accepted answer is-\n  [Id = 8567114] How to make an AJAX call without jQuery?\n\nAnd the top three most similar questions with accepted answers are\n  1. [Id = 890807] Iterate over a Javascript associative array in sorted order\n  2. [Id = 48863885] Converting array of object to en object with key : value dynamic\n  3. [Id = 417645] How to convert variable name to string in JavaScript?\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94c0de6a-5300-406f-973a-d3502c6bd109"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Solution","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3028321531459541}},"nbformat":4,"nbformat_minor":0}
